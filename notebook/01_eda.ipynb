{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6a0b0-b622-448f-8c1b-130f2a6e1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))  # Add project root to Python path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import *\n",
    "from src.features import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a412ca-3322-4402-add7-8027583fa84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_train_data()\n",
    "train = train_df.copy()\n",
    "test_df = load_test_data()\n",
    "test = test_df.copy()\n",
    "train = train.drop(columns='id')\n",
    "test = test.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259659ed-7bd8-46e6-894e-d5c2e16fda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59251049-4928-4f58-8673-8ad7733ed0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumetable2(df, target_col, missing_value=-1, ignore_cols=None, verbose=True):\n",
    "    ignore_cols = ignore_cols or []\n",
    "    if verbose:\n",
    "        print(f'Data shape: {df.shape}')\n",
    "\n",
    "    summary = pd.DataFrame(df.dtypes, columns=['Data Type'])\n",
    "    summary['Missing'] = (df == missing_value).sum().values\n",
    "    summary['Nunique'] = df.nunique().values\n",
    "    summary['Feature Type'] = None\n",
    "\n",
    "    for col in df.columns:\n",
    "        if 'target' in col:\n",
    "            summary.loc[col, 'Feature Type'] = 'Target'\n",
    "        elif 'bin' in col:\n",
    "            summary.loc[col, 'Feature Type'] = 'Binary'\n",
    "        elif 'cat' in col:\n",
    "            summary.loc[col, 'Feature Type'] = 'Categorical'\n",
    "        else:\n",
    "            summary.loc[col, 'Feature Type'] = 'Temp'\n",
    "            \n",
    "    summary = summary.sort_values(by='Feature Type')\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce718e-d92d-4eda-bf61-29dab92c44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table = resumetable2(train, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17e9e3-8127-4633-807e-b9e37b20e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = feature_table[feature_table['Feature Type'] == 'Categorical'].index.tolist()\n",
    "cat_cols = cat_cols + feature_table[feature_table['Feature Type'] == 'Binary'].index.tolist()\n",
    "cat_cols = cat_cols + feature_table[(feature_table['Nunique'] < 30) & (feature_table['Feature Type'] == 'Temp')].index.tolist()\n",
    "num_cols = feature_table[(feature_table['Nunique'] >= 30) & (feature_table['Feature Type'] == 'Temp')].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663082c-e2bd-4bef-8ca8-4fd9a15e4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f936fa9-d102-48d4-893a-24532f142ce8",
   "metadata": {},
   "source": [
    "1. value_counts: stratified kfold 사용 필요, 타겟값 불균형\n",
    "2. target 데이터부터 시각화 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5decc63d-dd02-4d74-b09f-b3671ec5fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=train, x='target')\n",
    "plt.title('Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00570f-e271-4079-8c30-7a8732edf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def gini_normalized(y_true, y_pred):\n",
    "    return 2 * roc_auc_score(y_true, y_pred) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5220def4-f81b-4efe-9c0f-d30c1f20fc8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pipeline -> Baseline model\n",
    "\n",
    "# 타겟 정의  \n",
    "X = train.drop(columns='target')\n",
    "y = train['target']\n",
    "\n",
    "# 전처리기 & 피처 생성기 정의 \n",
    "interaction_fe = InteractionFeatureGenerator()\n",
    "\n",
    "# 모델 정의 \n",
    "model = LGBMClassifier(random_state=42)\n",
    "\n",
    "# 파이프라인 생성 \n",
    "pipeline = make_pipeline(\n",
    "    interaction_fe,\n",
    "    model\n",
    ")\n",
    "\n",
    "# 교차 검증 및 평가 \n",
    "N_SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "    score = gini_normalized(y_val.values, y_pred_proba)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    print(f'Fold {fold+1} Gini Normalized: {score: .5f}')\n",
    "    \n",
    "# 결과\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "\n",
    "print(f'Baseline CV Score: {mean_cv_score: .5f} +/- {std_cv_score: .5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ab18b-bd4c-4e7b-a3a7-00ea952eca44",
   "metadata": {
    "tags": []
   },
   "source": [
    "### model.predict_proba()\n",
    "이진분류에서 predict_proba()는 2차원 배열을 반환 <br>\n",
    "y_pred_proba = model.predict_proba(X_val)<br>\n",
    "print(y_pred_proba.shape)  # (n_samples, 2)<br>\n",
    "print(y_pred_proba[:3])    # 처음 3개 샘플 예시<br>\n",
    "\n",
    "출력 예시:\n",
    "\n",
    "[[0.8, 0.2],   첫 번째 샘플: 80% 확률로 class 0, 20% 확률로 class 1 <br>\n",
    " [0.3, 0.7],   두 번째 샘플: 30% 확률로 class 0, 70% 확률로 class 1 <br>\n",
    " [0.9, 0.1]]   세 번째 샘플: 90% 확률로 class 0, 10% 확률로 class 1 <br>\n",
    " \n",
    "\n",
    "[:, 1]의 의미:<br>\n",
    "첫 번째 차원(행): 모든 샘플 선택 (:)<br>\n",
    "두 번째 차원(열): index 1 선택 (1) = class 1의 확률<br>\n",
    "y_pred_proba[:, 1]  # class 1 확률 (사고 날 확률) <- 우리가 원하는 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b932c18-998c-419a-a58e-f30fe55f0d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# param_sets = [\n",
    "#     # Baseline (현재)\n",
    "#     {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': -1},\n",
    "    \n",
    "#     # Set 1: 더 많은 트리, 낮은 학습률\n",
    "#     {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 7, 'num_leaves': 64},\n",
    "    \n",
    "#     # Set 2: 더 깊은 트리\n",
    "#     {'n_estimators': 1500, 'learning_rate': 0.03, 'max_depth': 8, 'num_leaves': 100},\n",
    "    \n",
    "#     # Set 3: 정규화 강화\n",
    "#     {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6, 'num_leaves': 50, \n",
    "#      'min_child_samples': 100, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "# ]\n",
    "\n",
    "# best_score = 0\n",
    "# best_params = None\n",
    "\n",
    "# for i, params in enumerate(param_sets):\n",
    "#     print(f\"\\n=== Testing Parameter Set {i+1} ===\")\n",
    "#     print(f\"Params: {params}\")\n",
    "    \n",
    "#     # 모델 생성\n",
    "#     model = LGBMClassifier(random_state=42, **params)\n",
    "    \n",
    "#     # 파이프라인 생성\n",
    "#     pipeline = make_pipeline(interaction_fe, model)\n",
    "    \n",
    "#     # CV 실행\n",
    "#     cv_scores = []\n",
    "#     for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "#         X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "#         X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "#         pipeline.fit(X_train, y_train)\n",
    "#         y_pred_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "#         score = gini_normalized(y_val.values, y_pred_proba)\n",
    "#         cv_scores.append(score)\n",
    "    \n",
    "#     # 결과 출력\n",
    "#     mean_score = np.mean(cv_scores)\n",
    "#     std_score = np.std(cv_scores)\n",
    "#     print(f\"CV Score: {mean_score:.5f} +/- {std_score:.5f}\")\n",
    "    \n",
    "#     # 최고 점수 업데이트\n",
    "#     if mean_score > best_score:\n",
    "#         best_score = mean_score\n",
    "#         best_params = params\n",
    "        \n",
    "# print(f\"\\n=== BEST RESULT ===\")\n",
    "# print(f\"Best Score: {best_score:.5f}\")\n",
    "# print(f\"Best Params: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698dcd1b-92b4-4a41-a0e6-2447bd6ed79a",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e13430-b38c-4845-896f-877bddb4a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_target = train.corr()['target'].abs().sort_values(ascending=False)\n",
    "# .abs(): 절댓값 제시, 타겟 예측에는 절댓값이 중요 \n",
    "print(corr_with_target.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fbb1d6-4552-43ee-b7fd-d17a978c094b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 원본으로 초기화\n",
    "train_data = train.copy()\n",
    "\n",
    "## Feature Engineering으로 무한 머리박기 \n",
    "\n",
    "\n",
    "# 타겟 정의  \n",
    "X = train_data.drop(columns='target')\n",
    "y = train_data['target']\n",
    "\n",
    "# 전처리기 & 피처 생성기 정의 \n",
    "# interaction_fe = InteractionFeatureGenerator()\n",
    "\n",
    "# 모델 정의 / 머리 박아보면서 feature engineering 검증 -> 파이프라인 없이 과정 최소화하며 바로 검증 \n",
    "model = LGBMClassifier(random_state=42)\n",
    "\n",
    "# 교차 검증 및 평가 \n",
    "N_SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    score = gini_normalized(y_val.values, y_pred_proba)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    print(f'Fold {fold+1} Gini Normalized: {score: .5f}')\n",
    "    \n",
    "# 결과\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "\n",
    "print(f'Feature Engineered CV Score: {mean_cv_score: .5f} +/- {std_cv_score: .5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68bd058-6bcf-4fa2-bc58-f2d15d625b1b",
   "metadata": {},
   "source": [
    "### 분석\n",
    "1. ps_ind_xx_bin: 거의 대부분의 feature가 의미 적음 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbc5ea-b34a-4cad-95f4-a04c5ad55e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "gain_importance = model.booster_.feature_importance(importance_type='gain')\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': gain_importance\n",
    "}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34c5f0-e6cf-4856-b930-0b92891bc186",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = feature_importance_df.head(10)\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ed064a-9b0f-41fd-b715-0228cc4ec08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features_names = feature_importance_df.head(10)['feature'].tolist()\n",
    "correlation_matrix = train[top_featuers_names].corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f7553-c90e-4c45-8925-6b2a70ce5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수와의 관계\n",
    "corr_with_target = train.corr()['target'].abs().sort_values(ascending=False)\n",
    "# .abs(): 절댓값 제시, 타겟 예측에는 절댓값이 중요 \n",
    "print(corr_with_target.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0814e95-8797-426b-9ca6-3113de0a2d34",
   "metadata": {},
   "source": [
    "## Insights\n",
    "1. reg_03/02/01은 서로 상관관계가 높음 그러나 reg_03은 importance가 굉장히 높은데 01/02는 그렇지 않음 하지만 target과의 corr값에서 02가 제일 높고 오히려 03이 그보다 낮으며, 01은 상위에 포함되지도 않음\n",
    "2. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64ea0e-56d7-47ae-8ff5-b1283ec7d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "generate_features(train, top_features_names)\n",
    "good_features = []\n",
    "for feat in new_features:\n",
    "    if quick_cv_test(feat) > threshold:\n",
    "        good_features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d5f46-c791-4c92-b335-2b2833f63f18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DriverPred)",
   "language": "python",
   "name": "driverpred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
